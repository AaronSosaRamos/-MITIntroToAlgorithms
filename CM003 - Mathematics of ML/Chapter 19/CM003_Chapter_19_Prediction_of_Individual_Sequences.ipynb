{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#PREDICTION OF INDIVIDUAL SEQUENCES"
      ],
      "metadata": {
        "id": "jmEZxSYdurBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Autoregressive Integrated Moving Average (ARIMA)"
      ],
      "metadata": {
        "id": "Lt8t1F8nvY2r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6mbrtI-uhDs",
        "outputId": "17eab735-16a5-4170-8a19-14823412970c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forecasted Value: 46.35089344762744\n",
            "MAE: 13.649106552372558\n",
            "RMSE: 13.649106552372558\n"
          ]
        }
      ],
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Example sequence data\n",
        "sequence_data = np.array([10, 20, 30, 40, 50])\n",
        "\n",
        "# Fit ARIMA model\n",
        "model = ARIMA(sequence_data, order=(1, 0, 0))\n",
        "model_fit = model.fit()\n",
        "\n",
        "# Forecast next value\n",
        "forecast_value = model_fit.forecast(steps=1)[0]\n",
        "\n",
        "# Evaluate model\n",
        "true_value = 60  # Actual next value\n",
        "mae = mean_absolute_error([true_value], [forecast_value])\n",
        "rmse = mean_squared_error([true_value], [forecast_value], squared=False)\n",
        "\n",
        "print(\"Forecasted Value:\", forecast_value)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"RMSE:\", rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Long Short-Term Memory (LSTM) Network"
      ],
      "metadata": {
        "id": "u-59NE_pvhrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Example sequence data (time series)\n",
        "sequence_data = np.array([[1, 2, 3], [2, 3, 4], [3, 4, 5]])\n",
        "target_values = np.array([4, 5, 6])\n",
        "\n",
        "# Reshape data for LSTM input (samples, timesteps, features)\n",
        "X_train = sequence_data.reshape((sequence_data.shape[0], sequence_data.shape[1], 1))\n",
        "\n",
        "# Build LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(sequence_data.shape[1], 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train LSTM model\n",
        "model.fit(X_train, target_values, epochs=100, verbose=0)\n",
        "\n",
        "# Predict next sequence value\n",
        "X_test = np.array([[4, 5, 6]])  # Next sequence to predict\n",
        "predicted_values = model.predict(X_test)\n",
        "\n",
        "# Evaluate model\n",
        "true_value = 7  # Actual next value\n",
        "mae = mean_absolute_error([true_value], predicted_values)\n",
        "rmse = mean_squared_error([true_value], predicted_values, squared=False)\n",
        "\n",
        "print(\"Predicted Value:\", predicted_values[0][0])\n",
        "print(\"MAE:\", mae)\n",
        "print(\"RMSE:\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo4kjDoQvidC",
        "outputId": "1fd6306f-845d-4cda-8cfc-baa2aaa0c5b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 346ms/step\n",
            "Predicted Value: 9.3935995\n",
            "MAE: 2.393599510192871\n",
            "RMSE: 2.393599510192871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Forest Regressor"
      ],
      "metadata": {
        "id": "d6eVOkQhvnHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Example sequence data\n",
        "X_train = np.array([[1], [2], [3]])\n",
        "y_train = np.array([2, 4, 6])\n",
        "\n",
        "# Fit Random Forest model\n",
        "model = RandomForestRegressor(n_estimators=100)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict next sequence value\n",
        "X_test = np.array([[4]])  # Next value to predict\n",
        "predicted_value = model.predict(X_test)\n",
        "\n",
        "# Evaluate model\n",
        "true_value = 8  # Actual next value\n",
        "mae = mean_absolute_error([true_value], [predicted_value])\n",
        "rmse = mean_squared_error([true_value], [predicted_value], squared=False)\n",
        "r2 = r2_score([true_value], [predicted_value])\n",
        "\n",
        "print(\"Predicted Value:\", predicted_value[0])\n",
        "print(\"MAE:\", mae)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2O_Sgl-vy6d",
        "outputId": "e44b38f3-7a5e-4e1d-c94b-ed1b07665530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Value: 5.24\n",
            "MAE: 2.76\n",
            "RMSE: 2.76\n",
            "R^2: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Support Vector Machine (SVM)"
      ],
      "metadata": {
        "id": "yANmL4mDv_xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Example sequence data\n",
        "X_train = np.array([[1], [2], [3]])\n",
        "y_train = np.array([2, 4, 6])\n",
        "\n",
        "# Fit SVM model\n",
        "model = SVR(kernel='rbf')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict next sequence value\n",
        "X_test = np.array([[4]])  # Next value to predict\n",
        "predicted_value = model.predict(X_test)\n",
        "\n",
        "# Evaluate model\n",
        "true_value = 8  # Actual next value\n",
        "mae = mean_absolute_error([true_value], [predicted_value])\n",
        "rmse = mean_squared_error([true_value], [predicted_value], squared=False)\n",
        "r2 = r2_score([true_value], [predicted_value])\n",
        "\n",
        "print(\"Predicted Value:\", predicted_value[0])\n",
        "print(\"MAE:\", mae)\n",
        "print(\"RMSE:\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij68BleJv10U",
        "outputId": "4812fa85-5052-44e8-e063-1db3a1a9fb9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Value: 4.223128789189343\n",
            "MAE: 3.776871210810657\n",
            "RMSE: 3.776871210810657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gradient Boosting Regressor"
      ],
      "metadata": {
        "id": "zvHd1WWAwF6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Example sequence data\n",
        "X_train = np.array([[1], [2], [3]])\n",
        "y_train = np.array([2, 4, 6])\n",
        "\n",
        "# Fit Gradient Boosting model\n",
        "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict next sequence value\n",
        "X_test = np.array([[4]])  # Next value to predict\n",
        "predicted_value = model.predict(X_test)\n",
        "\n",
        "# Evaluate model\n",
        "true_value = 8  # Actual next value\n",
        "mae = mean_absolute_error([true_value], [predicted_value])\n",
        "rmse = mean_squared_error([true_value], [predicted_value], squared=False)\n",
        "r2 = r2_score([true_value], [predicted_value])\n",
        "\n",
        "print(\"Predicted Value:\", predicted_value[0])\n",
        "print(\"MAE:\", mae)\n",
        "print(\"RMSE:\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia7b_n5wwGzQ",
        "outputId": "741c7fe5-59c4-41f1-bd64-785cdf508bf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Value: 5.999946877202226\n",
            "MAE: 2.000053122797774\n",
            "RMSE: 2.000053122797774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hidden Markov Model (HMM)"
      ],
      "metadata": {
        "id": "fTVJMtGIwJyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hmmlearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VmXJKFzwNSI",
        "outputId": "02ff6e84-e70e-4fce-8caf-88f4fc0756d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hmmlearn\n",
            "  Downloading hmmlearn-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/161.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/161.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.5.0)\n",
            "Installing collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from hmmlearn import hmm\n",
        "\n",
        "# Example sequence data\n",
        "X = np.array([[1], [2], [3]])\n",
        "\n",
        "# Fit HMM model\n",
        "model = hmm.GaussianHMM(n_components=3, covariance_type=\"full\")\n",
        "model.fit(X)\n",
        "\n",
        "# Predict next sequence value\n",
        "next_value = model.predict(np.array([[4]]))\n",
        "\n",
        "print(\"Next Predicted State:\", next_value[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_jHtR4uwKkP",
        "outputId": "ac49df8f-22b8-4c89-e9c3-17f8e41ba209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:hmmlearn.base:Fitting a model with 14 free scalar parameters with only 3 data points will result in a degenerate solution.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next Predicted State: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#K-Nearest Neighbors (KNN)"
      ],
      "metadata": {
        "id": "sK7MKVImwUeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Example sequence data\n",
        "X_train = np.array([[1], [2], [3]])\n",
        "y_train = np.array([2, 4, 6])\n",
        "\n",
        "# Fit KNN model\n",
        "model = KNeighborsRegressor(n_neighbors=3)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict next sequence value\n",
        "X_test = np.array([[4]])  # Next value to predict\n",
        "predicted_value = model.predict(X_test)\n",
        "\n",
        "# Evaluate model\n",
        "true_value = 8  # Actual next value\n",
        "mae = mean_absolute_error([true_value], [predicted_value])\n",
        "rmse = mean_squared_error([true_value], [predicted_value], squared=False)\n",
        "r2 = r2_score([true_value], [predicted_value])\n",
        "\n",
        "print(\"Predicted Value:\", predicted_value[0])\n",
        "print(\"MAE:\", mae)\n",
        "print(\"RMSE:\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ54J0CxwVD4",
        "outputId": "e330b55d-d280-482d-e441-618f33dd711c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Value: 4.0\n",
            "MAE: 4.0\n",
            "RMSE: 4.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gaussian Process Regression"
      ],
      "metadata": {
        "id": "rMR8AGZ9w_KP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Example sequence data\n",
        "X_train = np.array([[1], [2], [3]])\n",
        "y_train = np.array([2, 4, 6])\n",
        "\n",
        "# Define Gaussian Process kernel\n",
        "kernel = C(1.0, (1e-4, 1e1)) * RBF(1, (1e-4, 1e1))\n",
        "\n",
        "# Fit Gaussian Process model\n",
        "model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=0.1)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict next sequence value\n",
        "X_test = np.array([[4]])  # Next value to predict\n",
        "predicted_value, sigma = model.predict(X_test, return_std=True)\n",
        "\n",
        "# Evaluate model\n",
        "true_value = 8  # Actual next value\n",
        "mae = mean_absolute_error([true_value], [predicted_value])\n",
        "rmse = mean_squared_error([true_value], [predicted_value], squared=False)\n",
        "r2 = r2_score([true_value], [predicted_value])\n",
        "\n",
        "print(\"Predicted Value:\", predicted_value[0])\n",
        "print(\"MAE:\", mae)\n",
        "print(\"RMSE:\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s6VnBcHw_tH",
        "outputId": "1cf9ceed-de44-4723-8407-f882283b1d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Value: 6.4669350339689595\n",
            "MAE: 1.5330649660310405\n",
            "RMSE: 1.5330649660310405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extensions"
      ],
      "metadata": {
        "id": "hwDdA2vWxW1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Supervised Learning"
      ],
      "metadata": {
        "id": "6CI2IKUzxXVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris, load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.svm import SVC, SVR\n",
        "\n",
        "# Load Iris dataset (for classification)\n",
        "iris = load_iris()\n",
        "X_iris, y_iris = iris.data, iris.target\n",
        "\n",
        "# Split data into train and test sets for classification\n",
        "X_iris_train, X_iris_test, y_iris_train, y_iris_test = train_test_split(X_iris, y_iris, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features for classification\n",
        "scaler_iris = StandardScaler()\n",
        "X_iris_train_scaled = scaler_iris.fit_transform(X_iris_train)\n",
        "X_iris_test_scaled = scaler_iris.transform(X_iris_test)\n",
        "\n",
        "# Define classification models\n",
        "classification_models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Support Vector Machine\": SVC()\n",
        "}\n",
        "\n",
        "# Function to evaluate classification models\n",
        "def evaluate_classification_models(models, X_train, y_train, X_test, y_test):\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average='macro')\n",
        "        recall = recall_score(y_test, y_pred, average='macro')\n",
        "        f1 = f1_score(y_test, y_pred, average='macro')\n",
        "        results[name] = {\"Accuracy\": accuracy, \"Precision\": precision, \"Recall\": recall, \"F1-score\": f1}\n",
        "    return results\n",
        "\n",
        "# Evaluate classification models on Iris dataset\n",
        "classification_results = evaluate_classification_models(classification_models, X_iris_train_scaled, y_iris_train, X_iris_test_scaled, y_iris_test)\n",
        "\n",
        "# Load Breast Cancer dataset (for regression)\n",
        "cancer = load_breast_cancer()\n",
        "X_cancer, y_cancer = cancer.data, cancer.target\n",
        "\n",
        "# Split data into train and test sets for regression\n",
        "X_cancer_train, X_cancer_test, y_cancer_train, y_cancer_test = train_test_split(X_cancer, y_cancer, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features for regression\n",
        "scaler_cancer = StandardScaler()\n",
        "X_cancer_train_scaled = scaler_cancer.fit_transform(X_cancer_train)\n",
        "X_cancer_test_scaled = scaler_cancer.transform(X_cancer_test)\n",
        "\n",
        "# Define regression models\n",
        "regression_models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"K-Nearest Neighbors\": KNeighborsRegressor(),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(),\n",
        "    \"Random Forest\": RandomForestRegressor(),\n",
        "    \"Support Vector Machine\": SVR()\n",
        "}\n",
        "\n",
        "# Function to evaluate regression models\n",
        "def evaluate_regression_models(models, X_train, y_train, X_test, y_test):\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "        results[name] = {\"MAE\": mae, \"RMSE\": rmse}\n",
        "    return results\n",
        "\n",
        "# Evaluate regression models on Breast Cancer dataset\n",
        "regression_results = evaluate_regression_models(regression_models, X_cancer_train_scaled, y_cancer_train, X_cancer_test_scaled, y_cancer_test)\n",
        "\n",
        "# Display classification results\n",
        "print(\"Classification Results (Iris Dataset):\")\n",
        "for model, metrics in classification_results.items():\n",
        "    print(f\"{model}:\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"\\t{metric}: {value}\")\n",
        "\n",
        "# Display regression results\n",
        "print(\"\\nRegression Results (Breast Cancer Dataset):\")\n",
        "for model, metrics in regression_results.items():\n",
        "    print(f\"{model}:\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"\\t{metric}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4vWcyD9xupD",
        "outputId": "a582643d-1fbf-4ecb-ff85-26c9ec282005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Results (Iris Dataset):\n",
            "Logistic Regression:\n",
            "\tAccuracy: 1.0\n",
            "\tPrecision: 1.0\n",
            "\tRecall: 1.0\n",
            "\tF1-score: 1.0\n",
            "K-Nearest Neighbors:\n",
            "\tAccuracy: 1.0\n",
            "\tPrecision: 1.0\n",
            "\tRecall: 1.0\n",
            "\tF1-score: 1.0\n",
            "Decision Tree:\n",
            "\tAccuracy: 1.0\n",
            "\tPrecision: 1.0\n",
            "\tRecall: 1.0\n",
            "\tF1-score: 1.0\n",
            "Random Forest:\n",
            "\tAccuracy: 1.0\n",
            "\tPrecision: 1.0\n",
            "\tRecall: 1.0\n",
            "\tF1-score: 1.0\n",
            "Support Vector Machine:\n",
            "\tAccuracy: 1.0\n",
            "\tPrecision: 1.0\n",
            "\tRecall: 1.0\n",
            "\tF1-score: 1.0\n",
            "\n",
            "Regression Results (Breast Cancer Dataset):\n",
            "Linear Regression:\n",
            "\tMAE: 0.1969037446564639\n",
            "\tRMSE: 0.2531972797450529\n",
            "K-Nearest Neighbors:\n",
            "\tMAE: 0.06140350877192982\n",
            "\tRMSE: 0.19010615686293011\n",
            "Decision Tree:\n",
            "\tMAE: 0.07017543859649122\n",
            "\tRMSE: 0.26490647141300877\n",
            "Random Forest:\n",
            "\tMAE: 0.06807017543859649\n",
            "\tRMSE: 0.18428619999547424\n",
            "Support Vector Machine:\n",
            "\tMAE: 0.1276381828290622\n",
            "\tRMSE: 0.18798704463224564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Equivalence to Tail Bounds"
      ],
      "metadata": {
        "id": "jLiPIcS5zWtr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chernoff Bound Implementation"
      ],
      "metadata": {
        "id": "Gq8mDMa9zw2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def chernoff_bound(X, t):\n",
        "    \"\"\"\n",
        "    Compute the Chernoff bound for the sum of independent random variables.\n",
        "\n",
        "    Parameters:\n",
        "    X (list or np.array): List or array of independent random variables.\n",
        "    t (float): Tail parameter for the Chernoff bound.\n",
        "\n",
        "    Returns:\n",
        "    float: Upper bound on the tail probability.\n",
        "    \"\"\"\n",
        "    # Compute the mean of the random variables\n",
        "    mean_X = np.mean(X)\n",
        "\n",
        "    # Compute the sum of random variables\n",
        "    sum_X = np.sum(X)\n",
        "\n",
        "    # Compute the upper bound on the tail probability using the Chernoff bound formula\n",
        "    exponent = -t * (1 + t) * mean_X\n",
        "    upper_bound = np.exp(exponent)\n",
        "\n",
        "    return upper_bound\n",
        "\n",
        "# Example usage:\n",
        "# Assume X is a list/array of independent random variables\n",
        "X = [0.3, 0.5, 0.8, 0.2]\n",
        "t = 0.5\n",
        "bound = chernoff_bound(X, t)\n",
        "print(\"Chernoff Bound:\", bound)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR7z4NVgzXb7",
        "outputId": "5f60d1bd-a551-4282-b7a5-d3aa26281dc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chernoff Bound: 0.7135519747065024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hoeffding Inequality Implementation\n"
      ],
      "metadata": {
        "id": "Epxr2EqVzzEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def hoeffding_inequality(X, t):\n",
        "    \"\"\"\n",
        "    Compute the Hoeffding inequality for the sample mean of bounded random variables.\n",
        "\n",
        "    Parameters:\n",
        "    X (list or np.array): List or array of bounded random variables.\n",
        "    t (float): Tail parameter for the Hoeffding inequality.\n",
        "\n",
        "    Returns:\n",
        "    float: Upper bound on the tail probability.\n",
        "    \"\"\"\n",
        "    # Calculate the range of each random variable (assuming they are bounded)\n",
        "    a = np.min(X)\n",
        "    b = np.max(X)\n",
        "\n",
        "    # Compute the number of random variables\n",
        "    n = len(X)\n",
        "\n",
        "    # Compute the upper bound on the tail probability using the Hoeffding inequality formula\n",
        "    bound = np.exp(-2 * n * t**2 / ((b - a)**2))\n",
        "\n",
        "    return bound\n",
        "\n",
        "# Example usage:\n",
        "# Assume X is a list/array of bounded random variables\n",
        "X = [0.3, 0.5, 0.8, 0.2]  # Assuming each variable is in [0, 1]\n",
        "t = 0.5\n",
        "bound = hoeffding_inequality(X, t)\n",
        "print(\"Hoeffding Inequality Bound:\", bound)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ6Dv3Syz0Xf",
        "outputId": "ee8806cb-4347-40f0-ced3-d09fe26d1f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hoeffding Inequality Bound: 0.003865920139472811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bayessian Classifiers"
      ],
      "metadata": {
        "id": "KNRqO0sQz6aZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gaussian Naive-Bayes Classifier"
      ],
      "metadata": {
        "id": "xGhmZ7Q43HVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pgmpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISiJfBRk1tzv",
        "outputId": "8ecd58e5-c6b0-401b-92c6-b71ada87f5ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pgmpy\n",
            "  Downloading pgmpy-0.1.25-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.0.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.2.1+cu121)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pgmpy) (0.14.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pgmpy) (4.66.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.4.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pgmpy) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->pgmpy) (12.4.127)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->pgmpy) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pgmpy) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pgmpy) (1.3.0)\n",
            "Installing collected packages: pgmpy\n",
            "Successfully installed pgmpy-0.1.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from pgmpy.models import NaiveBayes\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Determine unique classes in target variable y\n",
        "classes = np.unique(y_train)\n",
        "\n",
        "# Initialize dictionary to store mean and standard deviation for each feature and class\n",
        "parameters = {}\n",
        "\n",
        "# Calculate mean and standard deviation for each feature in each class\n",
        "for c in classes:\n",
        "    # Filter training data by class\n",
        "    X_class = X_train_scaled[y_train == c]\n",
        "\n",
        "    # Calculate mean and standard deviation for each feature\n",
        "    class_params = {\n",
        "        'mean': np.mean(X_class, axis=0),\n",
        "        'std': np.std(X_class, axis=0)\n",
        "    }\n",
        "\n",
        "    # Store parameters for the class\n",
        "    parameters[c] = class_params\n",
        "\n",
        "# Make predictions using Gaussian Naive Bayes\n",
        "def predict_gaussian_naive_bayes(X_test, parameters):\n",
        "    y_pred = []\n",
        "\n",
        "    for x in X_test:\n",
        "        max_prob = -1\n",
        "        best_class = None\n",
        "\n",
        "        for c, params in parameters.items():\n",
        "            # Calculate class conditional probabilities using Gaussian distribution\n",
        "            likelihood = np.prod(norm.pdf(x, loc=params['mean'], scale=params['std']))\n",
        "\n",
        "            # Calculate prior probability (assume uniform prior)\n",
        "            prior = 1 / len(classes)\n",
        "\n",
        "            # Calculate posterior probability using Bayes' rule (without normalization)\n",
        "            posterior = likelihood * prior\n",
        "\n",
        "            # Choose the class with the highest posterior probability\n",
        "            if posterior > max_prob:\n",
        "                max_prob = posterior\n",
        "                best_class = c\n",
        "\n",
        "        y_pred.append(best_class)\n",
        "\n",
        "    return np.array(y_pred)\n",
        "\n",
        "# Make predictions on test data\n",
        "y_pred = predict_gaussian_naive_bayes(X_test_scaled, parameters)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "# Display evaluation metrics\n",
        "print(\"Gaussian Naive Bayes Classification Results (Iris Dataset - pgmpy):\\n\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pkqYRvf0Ph6",
        "outputId": "2a376ed5-63bb-4534-aa50-09554391e51e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gaussian Naive Bayes Classification Results (Iris Dataset - pgmpy):\n",
            "\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-score: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tabular CPD (Conditional Probability Distribution) Classifier"
      ],
      "metadata": {
        "id": "gUhlucAz3L8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "\n",
        "# Define a Bayesian model\n",
        "model = BayesianModel([('X', 'Y')])\n",
        "\n",
        "# Define Conditional Probability Distributions (CPDs)\n",
        "cpd_X = TabularCPD(variable='X', variable_card=2, values=[[0.6], [0.4]])\n",
        "cpd_Y_given_X = TabularCPD(variable='Y', variable_card=2,\n",
        "                           values=[[0.2, 0.7], [0.8, 0.3]],\n",
        "                           evidence=['X'], evidence_card=[2])\n",
        "\n",
        "# Add CPDs to the model\n",
        "model.add_cpds(cpd_X, cpd_Y_given_X)\n",
        "\n",
        "# Check model validity\n",
        "model.check_model()\n",
        "\n",
        "# Perform inference\n",
        "from pgmpy.inference import VariableElimination\n",
        "inference = VariableElimination(model)\n",
        "result = inference.query(variables=['Y'], evidence={'X': 0})\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZJve2iI21L2",
        "outputId": "e21c3a45-71fe-46b5-e916-6fb0f07cf22b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pgmpy:BayesianModel has been renamed to BayesianNetwork. Please use BayesianNetwork class, BayesianModel will be removed in future.\n",
            "WARNING:pgmpy:BayesianModel has been renamed to BayesianNetwork. Please use BayesianNetwork class, BayesianModel will be removed in future.\n",
            "WARNING:pgmpy:BayesianModel has been renamed to BayesianNetwork. Please use BayesianNetwork class, BayesianModel will be removed in future.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+\n",
            "| Y    |   phi(Y) |\n",
            "+======+==========+\n",
            "| Y(0) |   0.2000 |\n",
            "+------+----------+\n",
            "| Y(1) |   0.8000 |\n",
            "+------+----------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bayesian Network Classifier"
      ],
      "metadata": {
        "id": "kSxz_DEh3k_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "# Define a Bayesian Network model\n",
        "model = BayesianNetwork([('A', 'C'), ('B', 'C')])\n",
        "\n",
        "# Define sample data as a pandas DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'A': [0, 1, 0, 1],\n",
        "    'B': [0, 0, 1, 1],\n",
        "    'C': [0, 1, 1, 0]\n",
        "})\n",
        "\n",
        "# Learn parameters (CPDs) from data using Maximum Likelihood Estimation\n",
        "model.fit(data, estimator=MaximumLikelihoodEstimator)\n",
        "\n",
        "# Perform inference using Variable Elimination\n",
        "inference = VariableElimination(model)\n",
        "result = inference.query(variables=['C'], evidence={'A': 0, 'B': 1})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_vx6Arq26B0",
        "outputId": "08496775-7979-4527-a7a4-d81bcc6f9f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+\n",
            "| C    |   phi(C) |\n",
            "+======+==========+\n",
            "| C(0) |   0.0000 |\n",
            "+------+----------+\n",
            "| C(1) |   1.0000 |\n",
            "+------+----------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bayesian Belief Network (BBN) Classifier"
      ],
      "metadata": {
        "id": "_CdFJ80z3oWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "\n",
        "# Define a Bayesian Belief Network model\n",
        "model = BayesianModel([('X', 'Y'), ('Z', 'Y')])\n",
        "\n",
        "# Define Conditional Probability Distributions (CPDs) using TabularCPD\n",
        "cpd_X = TabularCPD(variable='X', variable_card=2, values=[[0.6], [0.4]])\n",
        "cpd_Z = TabularCPD(variable='Z', variable_card=2, values=[[0.7], [0.3]])\n",
        "cpd_Y_given_XZ = TabularCPD(variable='Y', variable_card=2,\n",
        "                            values=[[0.1, 0.9, 0.8, 0.7], [0.9, 0.1, 0.2, 0.3]],\n",
        "                            evidence=['X', 'Z'], evidence_card=[2, 2])\n",
        "\n",
        "# Add CPDs to the model\n",
        "model.add_cpds(cpd_X, cpd_Z, cpd_Y_given_XZ)\n",
        "\n",
        "# Check model validity\n",
        "model.check_model()\n",
        "\n",
        "# Perform inference\n",
        "from pgmpy.inference import VariableElimination\n",
        "inference = VariableElimination(model)\n",
        "result = inference.query(variables=['Y'], evidence={'X': 0, 'Z': 1})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gS8KgwM4D13",
        "outputId": "434e2bb3-842e-4193-9338-55df519522b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pgmpy:BayesianModel has been renamed to BayesianNetwork. Please use BayesianNetwork class, BayesianModel will be removed in future.\n",
            "WARNING:pgmpy:BayesianModel has been renamed to BayesianNetwork. Please use BayesianNetwork class, BayesianModel will be removed in future.\n",
            "WARNING:pgmpy:BayesianModel has been renamed to BayesianNetwork. Please use BayesianNetwork class, BayesianModel will be removed in future.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+\n",
            "| Y    |   phi(Y) |\n",
            "+======+==========+\n",
            "| Y(0) |   0.9000 |\n",
            "+------+----------+\n",
            "| Y(1) |   0.1000 |\n",
            "+------+----------+\n"
          ]
        }
      ]
    }
  ]
}