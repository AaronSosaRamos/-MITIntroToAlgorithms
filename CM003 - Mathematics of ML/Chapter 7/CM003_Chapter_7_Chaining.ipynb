{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Chaining"
      ],
      "metadata": {
        "id": "FVQcvqjFQ4Zv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stacking Models"
      ],
      "metadata": {
        "id": "-y5Cd5N0RQVe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1-Io6K0QiL3",
        "outputId": "e7ac1781-f8a6-4106-d7c7-8e7d8e23e0a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Regressor MSE: 0.28453653268650003\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the California Housing dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define base models\n",
        "base_models = [\n",
        "    ('rf', RandomForestRegressor(n_estimators=10, random_state=42)),\n",
        "    ('gb', GradientBoostingRegressor(n_estimators=10, random_state=42))\n",
        "]\n",
        "\n",
        "# Initialize the stacking regressor with a linear regression meta-model\n",
        "stacking_regressor = StackingRegressor(estimators=base_models, final_estimator=LinearRegression())\n",
        "\n",
        "# Train the stacking regressor\n",
        "stacking_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_stacking = stacking_regressor.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse_stacking = mean_squared_error(y_test, y_pred_stacking)\n",
        "print(f\"Stacking Regressor MSE: {mse_stacking}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ensembling models"
      ],
      "metadata": {
        "id": "uDai-X6qRg5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California Housing dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize base models\n",
        "model_rf = RandomForestRegressor(n_estimators=10, random_state=42)\n",
        "model_gb = GradientBoostingRegressor(n_estimators=10, random_state=42)\n",
        "\n",
        "# Create a voting regressor\n",
        "voting_regressor = VotingRegressor([('rf', model_rf), ('gb', model_gb)])\n",
        "\n",
        "# Train the voting regressor\n",
        "voting_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_voting = voting_regressor.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse_voting = mean_squared_error(y_test, y_pred_voting)\n",
        "print(f\"Voting Regressor MSE: {mse_voting}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04EzID1qRiKu",
        "outputId": "3d689ae4-c379-4dca-a75b-d8dd4ebc88b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting Regressor MSE: 0.376084845012778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Combining models in a Pipeline"
      ],
      "metadata": {
        "id": "CJqCVFyVRlM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California Housing dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a pipeline with preprocessing and modeling steps\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Standardize features\n",
        "    ('rf', RandomForestRegressor(n_estimators=10, random_state=42))  # Random Forest Regressor\n",
        "])\n",
        "\n",
        "# Train the pipeline (preprocessing + modeling)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_pipeline = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the pipeline\n",
        "mse_pipeline = mean_squared_error(y_test, y_pred_pipeline)\n",
        "print(f\"Pipeline MSE: {mse_pipeline}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGdhHxQVRnRu",
        "outputId": "228cd300-209e-439b-a845-5e9642310d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline MSE: 0.28364877522100695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Oracle Inequalities in Empirical Risk Minimization (ERM)"
      ],
      "metadata": {
        "id": "YPgNqJJXSI_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 1)\n",
        "y = 3 * X.squeeze() + np.random.randn(100)  # True relationship: y = 3*X + noise\n",
        "\n",
        "# Define a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model (empirical risk minimization)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Compute empirical risk (mean squared error)\n",
        "y_pred = model.predict(X)\n",
        "empirical_risk = mean_squared_error(y, y_pred)\n",
        "print(\"Empirical Risk (MSE):\", empirical_risk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUH_7GX-R8i_",
        "outputId": "42fcc0dc-6b9a-422f-ddc1-86d5e38ab30c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empirical Risk (MSE): 0.9924386487246483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sparse Recovery"
      ],
      "metadata": {
        "id": "fiopyQEcS0wG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cvxpy as cp\n",
        "\n",
        "# Generate synthetic data for sparse recovery\n",
        "np.random.seed(1)\n",
        "n = 100\n",
        "m = 50\n",
        "A = np.random.randn(m, n)  # Measurement matrix\n",
        "x_true = np.zeros(n)\n",
        "x_true[:5] = np.random.randn(5)  # True sparse signal\n",
        "y = A @ x_true + 0.1 * np.random.randn(m)  # Noisy measurements\n",
        "\n",
        "# Solve the L1-regularized least squares problem (Lasso)\n",
        "x = cp.Variable(n)\n",
        "objective = cp.Minimize(cp.norm(A @ x - y, 2) + cp.norm(x, 1))\n",
        "problem = cp.Problem(objective)\n",
        "\n",
        "# Solve the problem\n",
        "problem.solve()\n",
        "\n",
        "# Recovered sparse solution\n",
        "x_hat = x.value\n",
        "\n",
        "# Print the recovered sparse solution\n",
        "print(\"Recovered Sparse Solution:\", x_hat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goSIi32sSke-",
        "outputId": "2346d106-15ec-4b8f-a472-df4b834e9ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recovered Sparse Solution: [-8.86152430e-01  1.12920447e+00 -1.13031954e+00 -7.05358138e-01\n",
            "  6.44321781e-01 -4.83534711e-11 -4.10539223e-03  1.14299837e-11\n",
            " -3.81802557e-03 -1.05808494e-02 -1.81442205e-12  3.90384103e-11\n",
            "  3.22985132e-11 -1.11496500e-10 -2.51754896e-03 -1.22286683e-02\n",
            " -6.99323642e-03 -4.10945945e-12 -6.56299391e-04  2.64728074e-03\n",
            "  5.50285023e-11  1.60930172e-10 -1.79439661e-02  1.96893880e-10\n",
            "  1.18735866e-11  4.15756075e-10  7.58312822e-11 -1.01571788e-03\n",
            "  7.80468680e-11  1.49830239e-02 -1.37726113e-03  3.41513813e-11\n",
            "  8.70734940e-03 -1.09815788e-11  1.49596490e-11 -4.87341801e-11\n",
            " -1.22345860e-02 -2.29064836e-11 -1.02404709e-10 -1.93530087e-11\n",
            " -2.88515571e-02  3.53550822e-11 -1.07062049e-10  2.72508521e-11\n",
            " -1.83158188e-10  1.42064235e-11 -5.46078246e-03  1.61485052e-02\n",
            " -5.22370840e-11  5.57514736e-11 -1.99931300e-03 -2.44167564e-11\n",
            "  7.64980182e-03  6.09056084e-03 -1.40021301e-10 -1.80660045e-10\n",
            " -3.24209694e-03  7.06173670e-12 -3.56439167e-10  1.09318753e-11\n",
            " -1.67853362e-02 -6.02464031e-12  1.76938818e-11 -1.14023653e-10\n",
            "  1.37566099e-10 -8.56307058e-10  7.15027637e-11  1.76390209e-11\n",
            " -2.62154160e-12  1.92520392e-12  5.88336155e-03  5.33815367e-11\n",
            " -3.27524471e-11  7.14034615e-03  1.62124239e-04 -1.72115891e-10\n",
            " -1.65434088e-11  7.96388416e-12 -8.05669305e-11  8.19318118e-03\n",
            "  2.91351735e-11 -6.96343890e-11 -2.00813002e-02 -7.07377087e-11\n",
            " -1.70654563e-10  1.89392622e-10  3.51489288e-11 -4.24517034e-11\n",
            "  1.04486373e-02 -3.87551576e-11 -5.01563731e-11  4.84376639e-10\n",
            "  3.43694582e-03 -2.92482080e-11  6.05797050e-12 -8.00620759e-03\n",
            "  6.64114995e-11  7.24161453e-10  5.21289384e-11 -2.52509229e-11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Probability in a Banach Space (Finite-Dimensional Case)"
      ],
      "metadata": {
        "id": "7aPuB4vBS3Xu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "# Define parameters\n",
        "n = 3  # Dimension of the Banach space (e.g., Euclidean space R^n)\n",
        "mean = np.zeros(n)  # Mean vector\n",
        "covariance_matrix = np.eye(n)  # Identity covariance matrix (for simplicity)\n",
        "\n",
        "# Generate random vectors from a multivariate normal distribution\n",
        "num_samples = 1000\n",
        "random_vectors = multivariate_normal.rvs(mean=mean, cov=covariance_matrix, size=num_samples)\n",
        "\n",
        "# Compute sample mean and sample covariance\n",
        "sample_mean = np.mean(random_vectors, axis=0)\n",
        "sample_covariance = np.cov(random_vectors, rowvar=False)\n",
        "\n",
        "# Print results\n",
        "print(\"Sample Mean:\")\n",
        "print(sample_mean)\n",
        "print(\"\\nSample Covariance Matrix:\")\n",
        "print(sample_covariance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fv9zj_vSwGu",
        "outputId": "ceb89124-d942-4039-c579-3e11aeb8b891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Mean:\n",
            "[ 0.02092496 -0.05026219 -0.05075703]\n",
            "\n",
            "Sample Covariance Matrix:\n",
            "[[ 1.02566656 -0.06444956 -0.01811995]\n",
            " [-0.06444956  1.02612566 -0.00559662]\n",
            " [-0.01811995 -0.00559662  0.92482936]]\n"
          ]
        }
      ]
    }
  ]
}