# -*- coding: utf-8 -*-
"""CM003 - Chapter 12 - Projected Gradient Descent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hVmdkANxrVHhCPnLsCciSxD4wHauiRTd

#Projected Gradient Descent

![image.png](data:image/png;base64,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)
"""

import numpy as np

def projected_gradient_descent(f, grad_f, project, x0, lr=0.01, num_steps=100):
    """
    Projected Gradient Descent (PGD) for minimizing f(x) subject to the constraint x in C.

    Parameters:
        f (function): Objective function to minimize.
        grad_f (function): Gradient function of f.
        project (function): Projection function onto the feasible set C.
        x0 (numpy array): Initial point.
        lr (float): Learning rate or step size for gradient descent.
        num_steps (int): Number of PGD steps.

    Returns:
        numpy array: The optimized point x.
    """
    x = x0.copy()

    for _ in range(num_steps):
        gradient = grad_f(x)
        x = x - lr * gradient  # Gradient descent step
        x = project(x)         # Projection onto the feasible set C

    return x

# Example usage:
# Define the objective function and its gradient
def quadratic(x):
    return np.sum(x**2)

def grad_quadratic(x):
    return 2 * x

# Define the projection function onto a hypercube [a, b]
def project_hypercube(x, a=-1, b=1):
    return np.maximum(a, np.minimum(b, x))

# Set up parameters
np.random.seed(0)
x0 = np.random.randn(2)  # Initial point
lr = 0.1                 # Learning rate
num_steps = 100          # Number of PGD steps

# Run Projected Gradient Descent
x_opt = projected_gradient_descent(quadratic, grad_quadratic, project_hypercube, x0, lr=lr, num_steps=num_steps)

print("Optimal solution:", x_opt)
print("Optimal value of f(x):", quadratic(x_opt))

"""#Projection onto Closed Convex Set"""

import numpy as np
from scipy.optimize import minimize

def projection_onto_convex_set(x0, constraints):
    """
    Project a point x0 onto a closed convex set defined by linear inequality constraints.

    Parameters:
        x0 (numpy array): The point to project onto the convex set.
        constraints (list of dict): List of constraint dictionaries, each specifying a linear inequality constraint.
                                     Each dictionary has keys 'type', 'fun', and 'jac'.
                                     'type': Constraint type ('ineq' for inequality).
                                     'fun': Function defining the constraint (returns >= 0 for feasibility).
                                     'jac': Jacobian (gradient) of the constraint function.

    Returns:
        numpy array: The projected point onto the convex set.
    """
    # Define an objective function to minimize (distance from x0)
    def objective(y):
        return np.linalg.norm(y - x0)**2

    # Initialize optimization bounds (unconstrained)
    bounds = [(None, None) for _ in range(len(x0))]

    # Use scipy.optimize.minimize to perform the projection
    result = minimize(objective, x0, method='SLSQP', bounds=bounds, constraints=constraints)

    # Return the optimized point (projected point)
    return result.x

# Example usage:
if __name__ == "__main__":
    # Define the point x0 and constraints for a convex set (e.g., hypercube)
    x0 = np.array([1.5, 2.0, -1.0])

    # Define linear inequality constraints for a hypercube [a, b]^n (e.g., [-1, 1]^3)
    # Constraints: -1 <= x_i <= 1 for all i
    constraints = [
        {'type': 'ineq', 'fun': lambda x: x[0] - (-1), 'jac': lambda x: np.array([1.0, 0.0, 0.0])},  # x1 >= -1
        {'type': 'ineq', 'fun': lambda x: 1 - x[0], 'jac': lambda x: np.array([-1.0, 0.0, 0.0])},   # x1 <= 1
        {'type': 'ineq', 'fun': lambda x: x[1] - (-1), 'jac': lambda x: np.array([0.0, 1.0, 0.0])},  # x2 >= -1
        {'type': 'ineq', 'fun': lambda x: 1 - x[1], 'jac': lambda x: np.array([0.0, -1.0, 0.0])},   # x2 <= 1
        {'type': 'ineq', 'fun': lambda x: x[2] - (-1), 'jac': lambda x: np.array([0.0, 0.0, 1.0])},  # x3 >= -1
        {'type': 'ineq', 'fun': lambda x: 1 - x[2], 'jac': lambda x: np.array([0.0, 0.0, -1.0])}    # x3 <= 1
    ]

    # Project x0 onto the hypercube [-1, 1]^3
    projected_x = projection_onto_convex_set(x0, constraints)

    print("Original point x0:", x0)
    print("Projected point onto the hypercube [-1, 1]^3:", projected_x)

"""#Projected Gradient Descent"""

import numpy as np

def projected_gradient_descent(f, grad_f, project, x0, lr=0.01, num_steps=100, tol=1e-6):
    """
    Projected Gradient Descent (PGD) for minimizing f(x) subject to the constraint x in C.

    Parameters:
        f (function): Objective function to minimize.
        grad_f (function): Gradient function of f.
        project (function): Projection function onto the feasible set C.
        x0 (numpy array): Initial point.
        lr (float): Learning rate or step size for gradient descent.
        num_steps (int): Number of PGD steps.
        tol (float): Tolerance to stop optimization (based on change in x).

    Returns:
        numpy array: The optimized point x.
    """
    x = x0.copy()

    for i in range(num_steps):
        gradient = grad_f(x)
        x_new = x - lr * gradient  # Gradient descent step
        x_new = project(x_new)     # Projection onto the feasible set C

        # Check convergence based on change in x
        if np.linalg.norm(x_new - x) < tol:
            break

        x = x_new

    return x

# Example usage:
if __name__ == "__main__":
    # Define the objective function and its gradient
    def quadratic(x):
        return np.sum(x**2)

    def grad_quadratic(x):
        return 2 * x

    # Define the projection function onto a hypercube [a, b]
    def project_hypercube(x, a=-1, b=1):
        return np.maximum(a, np.minimum(b, x))

    # Set up parameters
    np.random.seed(0)
    x0 = np.random.randn(2)  # Initial point
    lr = 0.1                 # Learning rate
    num_steps = 100          # Number of PGD steps
    tol = 1e-6               # Tolerance for stopping criterion

    # Run Projected Gradient Descent
    x_opt = projected_gradient_descent(quadratic, grad_quadratic, project_hypercube, x0, lr=lr, num_steps=num_steps, tol=tol)

    print("Optimal solution:", x_opt)
    print("Optimal value of f(x):", quadratic(x_opt))

import numpy as np
from sklearn.datasets import make_classification
from sklearn.svm import SVC

# Generate synthetic data
X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, random_state=42)

# Initialize SVM model
svm = SVC(kernel='linear', C=1.0)

# Fit SVM model to the data
svm.fit(X, y)

# Get the learned parameters
w_svm = np.concatenate([svm.coef_.flatten(), [svm.intercept_[0]]])

# Define the hinge loss function for SVM
def hinge_loss(w, X, y, C=1.0):
    margin = y * (np.dot(X, w[:-1]) + w[-1])
    loss = np.maximum(0, 1 - margin)
    return C * np.mean(loss)

# Define the gradient of the hinge loss function for SVM
def grad_hinge_loss(w, X, y, C=1.0):
    margin = y * (np.dot(X, w[:-1]) + w[-1])
    indicator = (margin < 1).astype(int)
    grad = np.zeros_like(w)
    grad[:-1] = -C * np.mean((X.T * y * indicator).T, axis=0)
    grad[-1] = -C * np.mean(y * indicator)
    return grad

# Projected Gradient Descent function for SVM
def projected_gradient_descent_svm(X, y, C=1.0, lr=0.01, num_steps=100):
    w = np.zeros(X.shape[1] + 1)  # Initialize weights (including bias)
    for _ in range(num_steps):
        gradient = grad_hinge_loss(w, X, y, C=C)
        w_new = w - lr * gradient  # Gradient descent step
        # Projection onto the feasible set (L2 ball for SVM)
        norm = np.linalg.norm(w_new[:-1])
        if norm > np.sqrt(C):
            w_new[:-1] = w_new[:-1] * np.sqrt(C) / norm
        w = w_new
    return w

# Run Projected Gradient Descent for SVM
w_svm_pgd = projected_gradient_descent_svm(X, y)

print("Weights learned by SVM:", w_svm)
print("Weights learned by PGD for SVM:", w_svm_pgd)

import numpy as np
from sklearn.datasets import make_classification
from sklearn.tree import DecisionTreeRegressor

# Generate synthetic data
X_boost, y_boost = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, random_state=42)

# Initialize Boosting model
boosting = DecisionTreeRegressor(max_depth=1)

# Fit the first weak learner (initial constant prediction)
boosting.fit(X_boost, y_boost)

# Define the exponential loss function for Boosting
def exponential_loss(y_true, y_pred):
    return np.mean(np.exp(-y_true * y_pred))

# Define the gradient of the exponential loss function for Boosting
def grad_exponential_loss(y_true, y_pred):
    return -y_true * np.exp(-y_true * y_pred)

# Projected Gradient Descent function for Boosting
def projected_gradient_descent_boosting(X, y, lr=0.1, num_steps=100):
    predictions = np.zeros(len(y))  # Initialize predictions (initially zeros)
    for _ in range(num_steps):
        # Compute the gradient of the loss w.r.t. current predictions
        gradient = grad_exponential_loss(y, predictions)
        # Update the predictions using the gradient
        predictions -= lr * gradient
        # Project the predictions onto the feasible set (range of y)
        predictions = np.maximum(-1, np.minimum(1, predictions))
    return predictions

# Run Projected Gradient Descent for Boosting
predictions_boosting_pgd = projected_gradient_descent_boosting(X_boost, y_boost)

# Compute the coefficients based on the final predictions (for demonstration purposes)
# Handle division by zero gracefully
predictions_boosting_pgd = np.clip(predictions_boosting_pgd, -0.999999, 0.999999)
coeffs_boosting_pgd = 0.5 * np.log((1 + predictions_boosting_pgd) / (1 - predictions_boosting_pgd))

print("Coefficients learned by PGD for Boosting:", coeffs_boosting_pgd)

"""# Mirror Descent with  Bregman Projections"""

import numpy as np

def mirror_descent(f, grad_f, bregman_div, bregman_prox, x0, lr=0.1, num_steps=100):
    """
    Mirror Descent with Bregman Projections for minimizing f(x) subject to constraints defined by a Bregman divergence.

    Parameters:
        f (function): Objective function to minimize.
        grad_f (function): Gradient function of f.
        bregman_div (function): Bregman divergence function.
        bregman_prox (function): Bregman projection function.
        x0 (numpy array): Initial point.
        lr (float): Learning rate or step size for Mirror Descent.
        num_steps (int): Number of Mirror Descent steps.

    Returns:
        numpy array: The optimized point x.
    """
    x = x0.copy()

    for _ in range(num_steps):
        gradient = grad_f(x)
        x_new = x - lr * gradient  # Gradient descent step
        x_new = bregman_prox(x_new)  # Bregman projection onto the feasible set
        x = x_new

    return x

# Example usage:
if __name__ == "__main__":
    # Define the objective function and its gradient
    def quadratic(x):
        return np.sum(x**2)

    def grad_quadratic(x):
        return 2 * x

    # Define the Bregman divergence (squared Euclidean distance)
    def squared_euclidean_divergence(x, y):
        return np.sum((x - y)**2)

    # Define the Bregman projection onto the Euclidean ball (L2 norm ball)
    def euclidean_projection(x, center=np.zeros(2), radius=1.0):
        direction = x - center
        norm = np.linalg.norm(direction)
        if norm > radius:
            return center + (radius / norm) * direction
        else:
            return x

    # Set up parameters
    np.random.seed(0)
    x0 = np.random.randn(2)  # Initial point
    lr = 0.1                 # Learning rate
    num_steps = 100          # Number of Mirror Descent steps

    # Run Mirror Descent with Bregman Projections
    x_opt = mirror_descent(quadratic, grad_quadratic, squared_euclidean_divergence, euclidean_projection, x0, lr=lr, num_steps=num_steps)

    print("Optimal solution:", x_opt)
    print("Optimal value of f(x):", quadratic(x_opt))